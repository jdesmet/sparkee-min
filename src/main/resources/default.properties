# PLEASE DO NOT MODIFY THIS FILE

# for customizations, instead modify ${user.home}/.spark/default.properties
# ${user.home} is the home directory for the user where the spark job will run, which
# can be locally on your development machine (local maven profile), or remotely
# on the cluster, and the user on which you will run this job.

# From Unix Local File System:
#data.input.path: file:///home/spark/in

# From HDFS:
data.input.path: /user/spark/in

data.input.basename:INPUT
data.input.dateformat:yyyy-MM-dd

process.partitions: 20

# Do NOT store passwords in this file, as it will be under SVN control and have public access. In stead
# make sure to define it in ~/.spark/default.properties. When storing passwords in the
# local or remote location, make sure to apply proper access privileges, much the same way
# you would do so for ~/.ssh.

# db.[dbname].url=[jdbc resource as URL]
# db.[dbname].username=[username]
# db.[dbname].password=[Set in server-side ~/.spark/default.properties]

